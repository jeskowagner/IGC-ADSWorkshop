{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeskowagner/IGC-ADSWorkshop/blob/main/challenges/2023-05-12/parkinson-walkthrough-python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv_MNMTCjTgG"
      },
      "source": [
        "# Section 1: (Re)introduction of dataset & preparation [Reminder]\n",
        "\n",
        "This work-along demonstrates how Parkinson's can be predicted from speech patterns using statistics and machine learning in Python.\n",
        "\n",
        "It uses this (<https://archive.ics.uci.edu/ml/datasets/parkinsons>) dataset.\n",
        "\n",
        "The authors have kindly extracted some information from spoken interviews of participants.\n",
        "\n",
        "\n",
        "Generally, you can hover over the square brackets at the top left of the cell. When a white arrow inside a grey circle appears you can click this to run the cell.\n",
        "\n",
        "Hover your mouse over the bottom of a cell to see the options for new markdown or code cell pop up.\n",
        "\n",
        "We will get started right away by loading in everything we will need for this tutorial.\n",
        "\n",
        "You will notice towards the end of the cell we are defining a function to perform logistic regression on some inputs. If you have any questions about this please ask one of the organisers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkXHqU8GjU3R"
      },
      "outputs": [],
      "source": [
        "# Install shap for use later\n",
        "!pip install shap\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import shap\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import matthews_corrcoef, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Download the data\n",
        "!curl -o \"parkinsons.csv\" https://raw.githubusercontent.com/jeskowagner/IGC-ADSWorkshop/main/challenges/2023-05-12/parkinsons.csv\n",
        "\n",
        "\n",
        "# Set resolution of plots\n",
        "mpl.rcParams[\"figure.dpi\"] = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ml24u2erFL9s"
      },
      "outputs": [],
      "source": [
        "# Load in data and simplify for the purpose of this tutorial by choosing a few features.\n",
        "data = pd.read_csv(\"./parkinsons.csv\")\n",
        "data = data[[\"MDVP:Fo(Hz)\",'status', \"DFA\",\"spread1\", \"PPE\", \"D2\"]]\n",
        "\n",
        "#Create a function to generate and evaluate a model\n",
        "def Gen_and_Eval_Model(X_train, X_test, y_train, y_test):\n",
        "  \n",
        "  # Create an instance of the LogisticRegression class\n",
        "  model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "  # Fit the model to the training data\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # Predict probabilities for the test data\n",
        "  y_prob_pred = model.predict_proba(X_test) * 100\n",
        "\n",
        "  # Predict labels using a 50% threshold\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  # Format the predictions into a dataframe\n",
        "  y_prob_pred_df = pd.DataFrame(y_prob_pred, \n",
        "                              columns=[\"% No Parkinson's\", \"% Parkinson's\"], \n",
        "                              index=y_test.index)\n",
        "\n",
        "  y_prob_pred_df.insert(2, \"Predicted\", y_pred)\n",
        "\n",
        "  y_prob_pred_df.insert(0, \"Actual\", y_test)\n",
        "  y_prob_pred_df.groupby(\"Actual\").head(5)\n",
        "\n",
        "  ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=[\"Healthy\", \"Parkinson's\"])\n",
        "\n",
        "  # Calculate MCC on test data\n",
        "  mcc = matthews_corrcoef(y_test, y_pred)\n",
        "  print(\"MCC on test data:\", mcc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcvTHamyjTgI"
      },
      "source": [
        "# Section 2: reminder\n",
        "Some (many) datasets have missing values in them. We need to find these in order to train our model effectively. We can see an example NaN (\"Not a number\") in the very first cell!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IPshPKEv7dE"
      },
      "outputs": [],
      "source": [
        "# Print the top 5 rows of the data\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLyzqDiMlGoW"
      },
      "source": [
        "We can use a simple script here to give us the total missing values in the dataset. We need to use \".sum()\" twice because we are summing over both rows and columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVGlUma_wfew"
      },
      "outputs": [],
      "source": [
        "# Display the number of missing values in the whole dataset\n",
        "print(f\"There are {data.isna().sum().sum()} missing values\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbxzFvevlVk6"
      },
      "source": [
        "We can look at where these missing values appear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awDNdUP7kbRR"
      },
      "outputs": [],
      "source": [
        "# Find the columns with missing values in them.\n",
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjlXriyWwFXK"
      },
      "source": [
        "We can see here that all of the missing values are in a single column. In these cases it may be best simply to remove the troublesome column in order to train our model, and hope that the information in that column is not too important.\n",
        "\n",
        "If the missing values are spread throughout the dataset, we will need to use more advanced techniques to deal with the missingness, which we will cover later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3sLWzwO1kbt"
      },
      "source": [
        "# Section 3: Train/Test Split\n",
        "In machine learning, we often want to know how well our model performs on our data.\n",
        "\n",
        "But if we test a trained model on the same data it was trained on, our results will be biased: after all, the model has already seen the data it is being tested on.\n",
        "\n",
        "One of the ways to tackle this is to split your data into a training set and a test set.\n",
        "\n",
        "All decisions about the model are made on the training set, and the test set is exclusively used to evaluate the model in the end.\n",
        "\n",
        "In other words, we want to pause before starting with our analysis and set aside a portion of our data to test on later.\n",
        "\n",
        "In practice, this means that we often take, say, 80% of our observations for training, and 20% for testing.\n",
        "\n",
        "This could look like the following code. Note: you will have to fill something in for the proportion of the split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtLnS5up1h-c"
      },
      "outputs": [],
      "source": [
        "# Split the data into Train/Test\n",
        "\n",
        "# Remove the \"status\" column from the features and store it in the target variable\n",
        "\n",
        "# We will store variables used for prediction in \"X\" and the status of people (healthy, Parkinson's) in \"y\"\n",
        "X = data.drop(['status'], axis=1) # a dataframe of all variables we want to use to predict Parkinson's\n",
        "y = data['status'] # contains 1s and 0s\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "# Here (FILLMEIN) is where you can select the proportion of data used for testing: 0.5 would be half, 0.2 would be 20% etc.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2023, shuffle=True)\n",
        "\n",
        "# How many rows and columns are in the training and testing data?\n",
        "print(f\"Training Data Shape: {X_train.shape}\")\n",
        "print(f\"Training Labels Shape: {y_train.shape}\")\n",
        "\n",
        "print(f\"Testing Data Shape: {X_test.shape}\")\n",
        "print(f\"Testing Labels Shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9nIWLuA0sjk"
      },
      "source": [
        "# Section 4: Imputation\n",
        "\n",
        "Sometimes when collecting data, it is unfeasible to collect all data for all participants.\n",
        "\n",
        "**Exercise**: imagine a table with 10 patients, containing data of patients whose blood glucose and blood pressure were measured.\n",
        "\n",
        "For one patient we do not have the blood glucose level.\n",
        "\n",
        "Ultimately, we will need a dataset with no missing data to build our model.\n",
        "\n",
        "Speculate and discuss with your group how could you handle this missing case.\n",
        "\n",
        "Of course, the best solution would be to collect all data, but sometimes this may not be possible especially if there are patients involved.\n",
        "\n",
        "Finished the Exercise above? Good! Here are some ways you may have thought of:\n",
        "\n",
        "1.  Remove the patient from the dataset\n",
        "\n",
        "2.  Remove the measurement with missing values from the dataset\n",
        "\n",
        "3.  Calculate the average blood glucose level across the other patients and use that value for the missing patient\n",
        "\n",
        "4.  More advanced: use a machine learning model to predict the missing value\n",
        "\n",
        "All of them find use in real-world Science!\n",
        "\n",
        "\n",
        "We will create two new datasets with two different techniques for handling missingness. In the first one we simply remove the feature with missing values.\n",
        "\n",
        "In the second one we fill in missing values with the feature's mean value.\n",
        "\n",
        "\n",
        "Removing the rows with missing values in is an option, but is likely to introduce bias to the dataset. Why might this be?\n",
        "\n",
        "If the value is missing not at random (MNAR) then by removing it you are allowing the reason it is missing to bias the dataset. This in turn will mean that the model will learn incorrect associations and will not generalise to the true population you are studying. For further explanation please ask us!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnqzz43zxEjq"
      },
      "outputs": [],
      "source": [
        "X_train_dropped = X_train.drop([\"MDVP:Fo(Hz)\"], axis=1)\n",
        "X_test_dropped = X_test.drop([\"MDVP:Fo(Hz)\"], axis=1)\n",
        "\n",
        "X_train_imputed = X_train.fillna(X_train.mean())\n",
        "X_test_imputed = X_test.fillna(X_test.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CCFj-ly4bMX"
      },
      "source": [
        "We can see which of the two techniques for dealing with missing data is more effective for this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5dXdwBu4AbK"
      },
      "outputs": [],
      "source": [
        "Gen_and_Eval_Model(X_train_dropped, X_test_dropped, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sq3p94DT4jx3"
      },
      "outputs": [],
      "source": [
        "Gen_and_Eval_Model(X_train_imputed, X_test_imputed, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bndx5_ZD4wgO"
      },
      "source": [
        "In this case, the two models perform exactly the same as each other. This means that the feature itself was not important to the prediction. For the sake of argument, we will choose the imputation model to continue with.\n",
        "\n",
        "**Exercise**: does the result match your expectations? Why or why not?\n",
        "\n",
        "Brainstorm with your group about what could be done to improve the imputation strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju3B1hVY7LrT"
      },
      "outputs": [],
      "source": [
        "X_train = X_train_dropped\n",
        "X_test = X_test_dropped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MowbwiOSjTgJ"
      },
      "source": [
        "# Section 5: feature selection\n",
        "\n",
        "We can see that our predictions aren't perfect yet.\n",
        "\n",
        "One thing we can try is to cherry-pick some features and remove others.\n",
        "\n",
        "This process is called feature selection and often improves downstream performance.\n",
        "\n",
        "You can think of it as removing noise from the data: by removing surplus features, the model can focus on the features that are actually important.\n",
        "\n",
        "So, how do we select important features?\n",
        "\n",
        "There are a few different strategies, but to stay within time today we will focus on one: removing correlated features.\n",
        "\n",
        "Let's first look at correlations across our features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LYR6bmhtZeh"
      },
      "outputs": [],
      "source": [
        "corr_matrix = X_train.corrwith(y_train)\n",
        "print(corr_matrix)\n",
        "\n",
        "# Combine X_train and y_train into a single dataframe\n",
        "train_df = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "# Compute the pairwise correlations between all columns\n",
        "corr_matrix = train_df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR09pcNYyV7T"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(corr_matrix, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
        "plt.title(\"Pairwise Feature and Outcome Correlations\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e57j6W9t23FK"
      },
      "source": [
        "**Exercise**: remembering that the diagnosis (Parkinson's or healthy) is saved in the \"status\" column, which features correlate with the diagnosis?\n",
        "\n",
        "Conversely, which ones seems irrelevant?\n",
        "\n",
        "Which features have high correlation with each other?\n",
        "\n",
        "Sometimes, removing features that provide similar information can improve model performance.\n",
        "\n",
        "The idea behind this is to remove noise from our measurements and focus on features that provide unique information.\n",
        "\n",
        "Given the correlation plot we observed above, let's see how we could remove features that have high correlation to each other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ECk3ibvpoJ9"
      },
      "outputs": [],
      "source": [
        "# Drop one of each pair of correlated columns:\n",
        "X_train = X_train.drop([\"PPE\"], axis=1)\n",
        "X_test = X_test.drop([\"PPE\"], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRNYzy8g3Cvj"
      },
      "source": [
        "Did this improve our performance now? Let's check!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAqA_cRX3EKL"
      },
      "outputs": [],
      "source": [
        "Gen_and_Eval_Model(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DwJNt003JqG"
      },
      "source": [
        "**Exercise**: does the result match your expectations? Why or why not?\n",
        "\n",
        "Brainstorm with your group about what might have happened."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNl7uR3vjTgK"
      },
      "source": [
        "# Section 6: cross-validation\n",
        "\n",
        "Earlier we used a train/test split to build a model and evaluate its performance on held-out data.\n",
        "\n",
        "However, what if the split we used was unlucky and we got a bad split?\n",
        "\n",
        "To make sure we use each data point at least once for training and testing (separately), we can use cross-validation.\n",
        "\n",
        "Cross-validation is a really useful method because it helps us figure out how well our model will do on new, unseen data, without getting too caught up in the specifics of the data we used to train it.\n",
        "\n",
        "Plus, it helps us make sure our model isn't just memorizing the training data and isn't actually any good at generalizing to new examples.\n",
        "\n",
        "Cross-validation splits the dataset into `k` equal-sized folds and trains the model on `k`-1 folds while using the remaining fold as a test set.\n",
        "\n",
        "This process is repeated `k` times, each time using a different fold as the test set.\n",
        "\n",
        "The results from each fold are then averaged to obtain an overall estimate of model performance.\n",
        "\n",
        "This allows us to obtain a more robust estimate of the model's generalization performance and reduce the risk of overfitting to the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48y6YetPGaK4"
      },
      "outputs": [],
      "source": [
        "# Perform cross validation\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwD9znmK3g0Q"
      },
      "source": [
        "**Exercise**: What does this result mean?\n",
        "\n",
        "Brainstorm with your group about how to interpret this number."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9NEiM38jTgK"
      },
      "source": [
        "# Section 8: feature importance / model explainability\n",
        "\n",
        "If you've got this far, well done!\n",
        "\n",
        "Something else we can do with the model/data is to analyse feature importance with SHAP values (https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html)\n",
        "\n",
        "Which feature seems to  be doing all the heavy lifting?\n",
        "\n",
        "There are lots of other options for model explainability that we won't cover but have a google!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8WFGAcq5yj8"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Fits the explainer\n",
        "explainer = shap.Explainer(model.predict, X_test)\n",
        "# Calculates the SHAP values - It takes some time\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "shap.plots.bar(shap_values)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
